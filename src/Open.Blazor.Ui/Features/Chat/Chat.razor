@using Microsoft.SemanticKernel
@using Microsoft.SemanticKernel.ChatCompletion
@using Microsoft.SemanticKernel.Connectors.OpenAI
@using System.Text
@using Open.Blazor.Ui.Features.Shared.Models

@if (_discourse is not null && _activeOllamaModels is not null)
{
    <div class="settings">

        <FluentCard>
            <FluentLabel Typo="Typography.Header"> Chat Settings </FluentLabel>
            <FluentDivider Style="margin-top:10px;margin-bottom:10px;" />
            <FluentSelect TOption="OllamaModel"
                          Label="Model"
                          Items="@_activeOllamaModels.Models"
                          Id="listOfActiveModels"
                          Width="200px"
                          Style="margin:5px"
                          OptionText="@(p => p.Name)"
                          SelectedOption="_selectedModel"
                          SelectedOptionChanged="HandleSelectedOptionChanged" />
            <FluentSlider Id="temp-control" Label="@($"Temperature: {_temperature}")" @bind-Value="_temperature" Min="0" Max="2" Step=".1" Style="margin:5px" />
            <FluentTooltip Anchor="temp-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p>What it is: Think of it as a measure of creativity. </p>
                <p>How it works: Lower values make the model's responses more predictable and focused, while higher values make the responses more diverse and creative. </p>
                       </FluentTooltip>
            <FluentSlider Id="max-token-control" Label="@($"Max Tokens: {_maxTokens}")" @bind-Value="_maxTokens" Min="0" Max="4000" Step="10" Style="margin:5px" />
            <FluentTooltip Anchor="max-token-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p>What it is: Limits the length of the response.  </p>
                <p>How it works: It sets a maximum number of words or parts of words the model can generate in its response.  </p>
            </FluentTooltip>
            <FluentSlider Id="topp-control" Label="@($"Top P: {_topP}")" @bind-Value="_topP" Min="0" Max="2" Step=".1" Style="margin:5px" />
            <FluentTooltip Anchor="topp-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p>What it is: A method to control the randomness of the model's responses, often referred to as "nucleus sampling".  </p>
                <p>How it works: It looks at the top percentage of possibilities for the next word. If set to 1.0, it considers all possibilities (most random); if set to a lower value, it only considers the most likely options.  </p>
            </FluentTooltip>
            <FluentSlider Id="presence-penalty-control" Label="@($"Presence Penalty: {_presencePenalty}")" @bind-Value="_presencePenalty" Min="0" Max="2" Step=".1" Style="margin:5px" />
            <FluentTooltip Anchor="presence-penalty-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p> What it is: A way to encourage the model to talk about new topics. </p>
                <p>How it works: It reduces the likelihood of the model repeating the same words, promoting more varied responses.  </p>
            </FluentTooltip>
            <FluentSlider Id="frequency-penalty-control" Label="@($"Frequency Penalty: {_frequencyPenalty}")" @bind-Value="_frequencyPenalty" Min="0" Max="2" Step=".1" Style="margin:5px" />
            <FluentTooltip Anchor="frequency-penalty-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p>What it is: Similar to the presence penalty but focuses on how often words are used.  </p>
                <p>How it works: It discourages the model from using words too frequently, making the output more diverse. </p>
            </FluentTooltip>
            <FluentTextArea Id="system-prompt-control" Label="System Prompt" @bind-Value="_chatSystemPrompt" Cols="150"></FluentTextArea>
            <FluentTooltip Anchor="system-prompt-control"
                           Delay="300"
                           Position="TooltipPosition.End">
                <p>What it is: Information about the person using the model.  </p>
                <p>How it works: It might personalize the responses based on the user's identity or preferences. </p>
            </FluentTooltip>


        </FluentCard>
    </div>

    <div id="chat-window">

        @foreach (var message in _discourse.ChatMessages)
        {
            <ChatContent Message="message" ToastService="ToastService" JsRuntime="JsRuntime" />
        }

    </div>
    <div class="chat-box-container">
        <FluentTextArea @bind-Value=_userMessage Style="width:640px" Placeholder="Let's chat"></FluentTextArea>

        @if (!_isChatOngoing)
        {
            <FluentButton IconStart="@(new Icons.Filled.Size16.Send())" Style="margin-left:5px"
                          Appearance="Appearance.Stealth" OnClick="SendMessage" />
        }
        else
        {
            <FluentButton IconStart="@(new Icons.Filled.Size16.Stop())" Style="margin-left:5px"
                          Appearance="Appearance.Stealth" OnClick="StopChat" />
        }


    </div>
}

