@using Microsoft.SemanticKernel
@using Microsoft.SemanticKernel.ChatCompletion
@using Microsoft.SemanticKernel.Connectors.OpenAI
@using System.Text
@inject IJSRuntime JsRuntime
<h3>Basic Chat - Local llama 3</h3>

<FluentStack Id="chatWindow" Orientation="Orientation.Vertical"
             HorizontalAlignment="HorizontalAlignment.Center"
             VerticalAlignment="VerticalAlignment.Top"
             VerticalGap="20"
             Style="height: 85%;margin:10px;overflow-y:auto;padding:10px">

    @if (_chatMessages is not null)
    {
        @foreach (var message in _chatMessages)
        {
            <Chat Message="message" />
        }
    }
</FluentStack>

<FluentStack Orientation="Orientation.Horizontal"
             HorizontalAlignment="HorizontalAlignment.Center"
             VerticalAlignment="VerticalAlignment.Bottom">
    <FluentTextArea @bind-Value=_userMessage style="width:700px;margin-top:20px" Placeholder="Let's chat"></FluentTextArea>
    <FluentButton IconStart="@(new Icons.Regular.Size16.Send())"
                  Appearance="Appearance.Accent" OnClick="SendMessage" />
</FluentStack>

@code {
#pragma warning disable SKEXP0010
    private string _userMessage = string.Empty;

    private ChatHistory _chatHistory = new ChatHistory();
    private List<ChatMessage> _chatMessages = new List<ChatMessage>();
    private Kernel _kernel = default!;
    private IChatCompletionService _chatService = default!;

    protected override void OnInitialized()
    {

        var modelId = "llama3";//"mistral";

        var endpoint = new Uri("http://localhost:11434");

        var kernelBuilder = Kernel.CreateBuilder();
        _kernel = kernelBuilder
            .AddOpenAIChatCompletion(
                modelId,
                endpoint,
                apiKey: null)
            .Build();

        _chatService = _kernel.GetRequiredService<IChatCompletionService>();

        var executionSettings = new OpenAIPromptExecutionSettings
            {
                MaxTokens = 2000,
                Temperature = 0.5,
            };
    }

    private async Task SendMessage()
    {
        if (string.IsNullOrWhiteSpace(_userMessage)) return;


        var userMessage = new ChatMessage { Role = ChatRole.User, Content = _userMessage };
        _chatMessages.Add(userMessage);
        _chatHistory.AddUserMessage(_userMessage);
        _userMessage = string.Empty;
        StateHasChanged();

        var executionSettings = new OpenAIPromptExecutionSettings
            {
                MaxTokens = 2000,
                Temperature = 0.1,
            };

        var result = _chatService.GetStreamingChatMessageContentsAsync(
                                       _chatHistory,
                                       executionSettings: executionSettings,
                                       kernel: _kernel);


        var assistantMessage = new ChatMessage { Role = ChatRole.Assistant, Content = string.Empty };
        _chatMessages.Add(assistantMessage);
        StateHasChanged();

        var sb = new StringBuilder();
        await foreach (var content in result)
        {
            sb.Append(content.Content);
            assistantMessage.Content = sb.ToString();
            await InvokeAsync(StateHasChanged);
            await ScrollToBottom();
        }

        _chatHistory.AddAssistantMessage(assistantMessage.Content);
    }

    private async Task ScrollToBottom()
    {
        await JsRuntime.InvokeVoidAsync("ScrollToBottom", "chatWindow");
    }
}
